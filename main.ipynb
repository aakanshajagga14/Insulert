import os
import time
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf

from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    confusion_matrix,
    classification_report,
    roc_auc_score
)

from tensorflow.keras import layers, models, callbacks

# -------------------------------------------------------------------
# Reproducibility
# -------------------------------------------------------------------
SEED = 42
np.random.seed(SEED)
tf.random.set_seed(SEED)

# -------------------------------------------------------------------
# Config
# -------------------------------------------------------------------
DATA_DIR = "../input/prepossessed-arrays-of-binary-data"
INFO_CSV = os.path.join(DATA_DIR, "1000_Binary Dataframe")
BATCH_SIZE = 16
EPOCHS = 30
VAL_SPLIT = 0.2

# -------------------------------------------------------------------
# Data loading
# -------------------------------------------------------------------
info = pd.read_csv(INFO_CSV)
if "Unnamed: 0" in info.columns:
    info = info.drop(columns=["Unnamed: 0"])

y = info["level"].values.astype("int32")
num_classes = len(np.unique(y))

def load_binary_images(size: int) -> np.ndarray:
    file_map = {
        90: "1000_Binary_images_data_90.npz",
        128: "1000_Binary_images_data_128.npz",
        264: "1000_Binary_images_data_264.npz",
    }
    path = os.path.join(DATA_DIR, file_map[size])
    arr = np.load(path)["a"]
    arr = arr.reshape(-1, size, size, 3).astype("float32") / 255.0
    return arr

# -------------------------------------------------------------------
# Model factory
# -------------------------------------------------------------------
def build_cnn(input_shape, n_classes: int) -> tf.keras.Model:
    inputs = layers.Input(shape=input_shape)

    x = layers.Conv2D(32, 3, padding="same", activation="relu")(inputs)
    x = layers.BatchNormalization()(x)
    x = layers.MaxPooling2D(2)(x)

    x = layers.Conv2D(64, 3, padding="same", activation="relu")(x)
    x = layers.BatchNormalization()(x)
    x = layers.MaxPooling2D(2)(x)

    x = layers.Conv2D(128, 3, padding="same", activation="relu")(x)
    x = layers.BatchNormalization()(x)
    x = layers.MaxPooling2D(2)(x)

    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dropout(0.5)(x)
    outputs = layers.Dense(n_classes, activation="softmax")(x)

    model = models.Model(inputs, outputs)
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),
        loss="sparse_categorical_crossentropy",
        metrics=["accuracy"],
    )
    return model

# -------------------------------------------------------------------
# Training + evaluation for one resolution
# -------------------------------------------------------------------
def train_and_evaluate(size: int):
    print(f"\n===== Resolution: {size}x{size} =====")
    X = load_binary_images(size)

    X_train, X_val, y_train, y_val = train_test_split(
        X,
        y,
        test_size=VAL_SPLIT,
        random_state=SEED,
        stratify=y,
    )

    model = build_cnn(input_shape=X_train.shape[1:], n_classes=num_classes)
    model.summary()

    cbs = [
        callbacks.EarlyStopping(
            monitor="val_loss",
            patience=5,
            restore_best_weights=True,
        ),
        callbacks.ReduceLROnPlateau(
            monitor="val_loss",
            factor=0.5,
            patience=2,
            verbose=1,
        ),
    ]

    t0 = time.time()
    history = model.fit(
        X_train,
        y_train,
        validation_data=(X_val, y_val),
        epochs=EPOCHS,
        batch_size=BATCH_SIZE,
        callbacks=cbs,
        verbose=1,
    )
    train_time = time.time() - t0

    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)
    print(f"Val loss: {val_loss:.4f} | Val acc: {val_acc:.4f}")
    print(f"Train time: {train_time:.1f}s")

    y_prob = model.predict(X_val, batch_size=BATCH_SIZE)
    y_pred = np.argmax(y_prob, axis=1)

    print("\nClassification report:")
    print(classification_report(y_val, y_pred))

    cm = confusion_matrix(y_val, y_pred)
    plt.figure(figsize=(5, 4))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
    plt.title(f"Confusion matrix ({size}x{size})")
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.tight_layout()
    plt.show()

    # Example macro AUC for binary or multi-class
    try:
        auc_macro = roc_auc_score(y_val, y_prob, multi_class="ovr")
        print(f"Macro ROC-AUC: {auc_macro:.4f}")
    except ValueError:
        pass

    return {
        "size": size,
        "val_acc": float(val_acc),
        "val_loss": float(val_loss),
        "train_time": float(train_time),
    }

# -------------------------------------------------------------------
# Run experiments
# -------------------------------------------------------------------
if __name__ == "__main__":
    results = []
    for s in (90, 128, 264):
        results.append(train_and_evaluate(s))

    print("\nSummary:")
    for r in results:
        print(
            f"{r['size']}x{r['size']} -> "
            f"val_acc={r['val_acc']:.4f}, "
            f"val_loss={r['val_loss']:.4f}, "
            f"time={r['train_time']:.1f}s"
        )
